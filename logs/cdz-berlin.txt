2025-12-21 06:38:21 [scrapy.utils.log] INFO: Scrapy 2.13.4 started (bot: nebi_spiders)
2025-12-21 06:38:21 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.11.14 (main, Oct 10 2025, 01:03:14) [GCC 13.3.0]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'Linux-6.11.0-1018-azure-x86_64-with-glibc2.39'}
2025-12-21 06:38:21 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): cdz-berlin.de:443
2025-12-21 06:38:24 [urllib3.connectionpool] DEBUG: https://cdz-berlin.de:443 "GET /allgemeine_geschaeftsbedingungen HTTP/1.1" 503 None
Unhandled error in Deferred:
2025-12-21 06:38:24 [twisted] CRITICAL: Unhandled error in Deferred:

Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/twisted/internet/defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/crawler.py", line 153, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/crawler.py", line 166, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/spiders/__init__.py", line 74, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/runner/work/nebi-scraper/nebi-scraper/nebi_spiders/spiders/berlin/cdz_berlin.py", line 29, in __init__
    self.max_rental_period = re.findall(r'(?<=bis zu )(\d+)(?= Tagen)', page.text)[0]
builtins.IndexError: list index out of range

2025-12-21 06:38:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/twisted/internet/defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/crawler.py", line 153, in crawl
    self.spider = self._create_spider(*args, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/crawler.py", line 166, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scrapy/spiders/__init__.py", line 74, in from_crawler
    spider = cls(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/runner/work/nebi-scraper/nebi-scraper/nebi_spiders/spiders/berlin/cdz_berlin.py", line 29, in __init__
    self.max_rental_period = re.findall(r'(?<=bis zu )(\d+)(?= Tagen)', page.text)[0]
                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
